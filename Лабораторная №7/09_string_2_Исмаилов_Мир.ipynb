{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pymorphy2\n",
    "from nltk.metrics import *\n",
    "from nltk.metrics.distance import (\n",
    "    edit_distance,\n",
    "    edit_distance_align,\n",
    "    binary_distance,\n",
    "    jaccard_distance,\n",
    "    masi_distance,\n",
    "    interval_distance,\n",
    "    custom_distance,\n",
    "    presence,\n",
    "    fractional_presence,\n",
    ")\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий\n",
      "Corr: с 26 величайшим 42 усилием 4 выбравшись из 6 потока 1 убегающих 761 людей 5 кутузову со 3 свитой 1 уменьшившейся 65 вдвое 2 поехало на 108 звуки 9 выстрелов 1 прусских 30 орудий\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "# читаем слова из файла\n",
    "with open('litw-win.txt', 'r') as f:\n",
    "    words = [word.strip() for word in f]\n",
    "\n",
    "def correct_sentence(sentence):\n",
    "    corrected = []\n",
    "    for word in sentence.split():\n",
    "        if word not in words:\n",
    "            # ищем ближайшее слово из списка\n",
    "            closest = difflib.get_close_matches(word, words, n=1)\n",
    "            if closest:\n",
    "                corrected.append(closest[0])\n",
    "            else:\n",
    "                corrected.append(word)\n",
    "        else:\n",
    "            corrected.append(word)\n",
    "    return ' '.join(corrected)\n",
    "\n",
    "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''\n",
    "correct = correct_sentence(text)\n",
    "print(f'Orig: {text}')\n",
    "print(f'Corr: {correct}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# #разбиение на слова\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# ww = 'Считайте слова из файла и запишите их в список. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка. Считайте, что в слове есть опечатка, если данное слово не содержится в списке. '\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# z = ww.split()\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m#for i in z:\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39m#print(snb_stemmer_ru.stem(i))\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m morphhhh \u001b[39m=\u001b[39m pymorphy2\u001b[39m.\u001b[39;49mMorphAnalyzer()\n\u001b[0;32m     11\u001b[0m \u001b[39m# for i in z:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#     print(morph.parse(i))\u001b[39;00m\n\u001b[0;32m     14\u001b[0m p \u001b[39m=\u001b[39m morphhhh\u001b[39m.\u001b[39mparse(\u001b[39m'\u001b[39m\u001b[39mкошка\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mirqa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[1;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_type_orig \u001b[39m=\u001b[39m result_type\n\u001b[0;32m    223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[1;32m--> 224\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_units(units)\n",
      "File \u001b[1;32mc:\\Users\\mirqa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[1;34m(self, units_unbound)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m item[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 235\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_unit(unit), \u001b[39mFalse\u001b[39;00m))\n\u001b[0;32m    236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_units\u001b[39m.\u001b[39mappend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_unit(item[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), \u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mirqa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[1;34m(self, unit)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_bound_unit\u001b[39m(\u001b[39mself\u001b[39m, unit):\n\u001b[1;32m--> 246\u001b[0m     unit \u001b[39m=\u001b[39m unit\u001b[39m.\u001b[39;49mclone()\n\u001b[0;32m    247\u001b[0m     unit\u001b[39m.\u001b[39minit(\u001b[39mself\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[39mreturn\u001b[39;00m unit\n",
      "File \u001b[1;32mc:\\Users\\mirqa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_params())\n",
      "File \u001b[1;32mc:\\Users\\mirqa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     74\u001b[0m     \u001b[39m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[1;32m---> 76\u001b[0m         (key, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, key, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_param_names()\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mirqa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pymorphy2\\units\\base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m:\n\u001b[0;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[1;32m---> 70\u001b[0m args, varargs, kw, default \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetargspec(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msorted\u001b[39m(args[\u001b[39m1\u001b[39m:])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "# #разбиение на слова\n",
    "# ww = 'Считайте слова из файла и запишите их в список. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка. Считайте, что в слове есть опечатка, если данное слово не содержится в списке. '\n",
    "# z = ww.split()\n",
    "# print(z)\n",
    "\n",
    "#snb_stemmer_ru = SnowballStemmer('russian')\n",
    "#for i in z:\n",
    "    #print(snb_stemmer_ru.stem(i))\n",
    "    \n",
    "morphhhh = pymorphy2.MorphAnalyzer()\n",
    "# for i in z:\n",
    "#     print(morph.parse(i))\n",
    "\n",
    "p = morphhhh.parse('кошка')\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
